# ðŸ§‘â€âœˆï¸ Multi-Agent Workflow with Flight & Hotel Booking  

This project implements a **LangGraph + LangChain** multi-agent system with support for **flight booking, hotel booking, and workflow orchestration**.  
It integrates:  
- **Custom ReAct Agents** with tool access (SQL, DB operations).  
- **Workflow orchestration** using `WorkflowBuilder`.  
- **Monitoring** via **Prometheus** and **MLflow**.  
- **Persistence** with **SQLite databases** (flights, hotels, bookings).  

---

## ðŸ“‚ Project Structure  

```
.
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ workflow_builder.py   # Workflow orchestration and supervisor
â”‚   â”œâ”€â”€ agent_builder.py      # Configurable ReAct agent class
â”‚   â”œâ”€â”€ tools_builder.py      # Flight + Hotel booking tools
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ workflow.yaml         # Workflow configuration
â”‚   â”œâ”€â”€ agents.yaml           # Agents definition (names, tools, prompts)
â”‚   â””â”€â”€ prompts.yaml          # Prompts if not loaded from MLflow
â”‚
â”œâ”€â”€ databases/                # SQLite DBs (flights, hotels, bookings)
â”œâ”€â”€ libs/
â”‚   â””â”€â”€ mlflow_utils.py       # MLflow logging helpers
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup  

### 1. Install dependencies (local)  
```bash
pip install -r requirements.txt
```

### 2. Environment Variables  
Create a `.env` file with:  
```env
GROQ_API_KEY=your_groq_api_key
MLFLOW_TRACKING_URI=http://mlflow:5000
MLFLOW_EXPERIMENT=genai_ops_demo
```

### 3. Initialize databases (only first run)  
```bash
python -c "from core.tools_builder import init_flight_bookings_db, init_hotel_bookings_db; print(init_flight_bookings_db()); print(init_hotel_bookings_db())"
```

---

## ðŸš€ Quickstart Demo (5 minutes)  

Follow these steps to **book a flight, check status, cancel it, and query hotels**.  

### Step 1 â€“ Start the workflow  
```bash
python core/workflow_builder.py
```

### Step 2 â€“ Search flights  
```
You: Find me a flight from Delhi to Mumbai on 2025-09-01
Response: [
  {
    "flight_id": "AI202",
    "departure_airport": "DEL",
    "arrival_airport": "BOM",
    "airline": "Air India",
    ...
  }
]
```

### Step 3 â€“ Book a flight  
```
You: Book flight AI202 for John Doe, email john@example.com, phone 9998887777
Response: "Booking BK202508261200ABCD saved successfully."
```

### Step 4 â€“ Check booking status  
```
You: What is the status of my booking BK202508261200ABCD?
Response: {
  "booking_id": "BK202508261200ABCD",
  "name": "John Doe",
  "status": "Confirmed",
  ...
}
```

### Step 5 â€“ Cancel booking  
```
You: Cancel booking BK202508261200ABCD
Response: "Booking BK202508261200ABCD cancelled."
```

### Step 6 â€“ Search hotels  
```
You: Show me hotels in Mumbai
Response: [
  {
    "hotel_name": "Taj Mumbai",
    "address": "Apollo Bandar, Colaba",
    "phone": "022-6665-1234",
    "rooms": 120
  },
  ...
]
```

ðŸŽ‰ Thatâ€™s it! Youâ€™ve tested the **entire workflow** in under 5 minutes.  

---

## ðŸ³ Docker Deployment  

You can run everything with **Docker Compose**.  

### 1. Dockerfile (for workflow service)  
```dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["python", "core/workflow_builder.py"]
```

### 2. docker-compose.yml  
```yaml
version: "3.9"

services:
  workflow:
    build: .
    container_name: workflow_service
    env_file: .env
    volumes:
      - ./databases:/app/databases
    ports:
      - "8000:8000"   # FastAPI endpoints (if used)
      - "9090:9090"   # Prometheus scrape port

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: mlflow
    command: >
      mlflow server
      --backend-store-uri sqlite:///mlflow.db
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
      --port 5000
    volumes:
      - ./mlruns:/mlflow
    ports:
      - "5000:5000"

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9091:9090"
```

### 3. Prometheus config (`prometheus.yml`)  
```yaml
global:
  scrape_interval: 5s

scrape_configs:
  - job_name: "workflow"
    static_configs:
      - targets: ["workflow:9090"]
```

### 4. Run all services  
```bash
docker-compose up --build
```

### 5. Access services  
- **Workflow** â†’ `http://localhost:8000`  
- **MLflow UI** â†’ `http://localhost:5000`  
- **Prometheus** â†’ `http://localhost:9091`  

---

## ðŸ“Š Monitoring  

- **Prometheus** collects:
  - `workflow_runs_total`  
  - `workflow_errors_total`  
  - `workflow_latency_seconds`  
  - `workflow_active_threads`  

- **MLflow** logs:
  - `agent_name`, `model`, `latency`, `tokens`, `response_length`.  

---

## âœ… Roadmap  

- [ ] Add car rentals & food ordering agents  
- [ ] Grafana dashboards (next to Prometheus)  
- [ ] Kubernetes Helm charts for scaling  
