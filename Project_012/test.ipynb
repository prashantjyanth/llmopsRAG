{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c718a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "configs = yaml.safe_load(open(\"configs/agents.yaml\", \"r\"))\n",
    "import yaml\n",
    "from core.agent_builder import ConfigReactAgent\n",
    "\n",
    "# with open(\"config.yaml\") as f:\n",
    "#     config = yaml.safe_load(f)\n",
    "\n",
    "flight_cfg = configs[\"agents\"][\"flight_agent\"]\n",
    "\n",
    "# Create agent with MLflow prompt preference\n",
    "flight_agent = ConfigReactAgent(\"flight_agent\", flight_cfg)\n",
    "\n",
    "response = flight_agent.run(\"Cancel my booking with booking_id=12345\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b721243e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from libs.governance_decorator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "194b0eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'content': 'search flight from new york to seattle on 15/08/2015', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '16b5ac43-c87b-482a-8aa6-c4380d2d2877', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'ejsx7shjj', 'function': {'arguments': '{\"date\":\"15/08/2015\",\"destination\":\"Seattle\",\"origin\":\"New York\"}', 'name': 'transfer_to_flight_agent'}, 'type': 'function'}]}, 'response_metadata': {'token_usage': {'completion_tokens': 63, 'prompt_tokens': 943, 'total_tokens': 1006, 'completion_time': 0.129330526, 'prompt_time': 0.076587669, 'queue_time': 0.266737131, 'total_time': 0.205918195}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_de9fa14705', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': 'supervisor', 'id': 'run--c40401c5-88eb-4fe3-9d9a-50b8ee7212f9-0', 'example': False, 'tool_calls': [{'name': 'transfer_to_flight_agent', 'args': {'date': '15/08/2015', 'destination': 'Seattle', 'origin': 'New York'}, 'id': 'ejsx7shjj', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 943, 'output_tokens': 63, 'total_tokens': 1006}}, {'content': 'Successfully transferred to flight_agent', 'additional_kwargs': {}, 'response_metadata': {'__handoff_destination': 'flight_agent'}, 'type': 'tool', 'name': 'transfer_to_flight_agent', 'id': '1e1ede6e-b545-416a-8a77-c38021996074', 'tool_call_id': 'ejsx7shjj', 'artifact': None, 'status': 'success'}, {'content': '**Flight Search Results**\\n==========================\\n\\nHere are the search results for flights from New York to Seattle on 15/08/2015:\\n\\n**Flights Found:** 6\\n\\n**Flight Details:**\\n\\n* **Flight 1:** DL422, Departing JFK at 07:10, Arriving SEA at 10:07\\n* **Flight 2:** DL467, Departing JFK at 10:45, Arriving SEA at 13:49\\n* **Flight 3:** DL419, Departing JFK at 15:50, Arriving SEA at 19:15\\n* **Flight 4:** B6263, Departing JFK at 17:36, Arriving SEA at 20:59\\n* **Flight 5:** AA45, Departing JFK at 18:30, Arriving SEA at 22:05\\n* **Flight 6:** DL427, Departing JFK at 18:50, Arriving SEA at 22:25\\n\\n**Tables Used:** `flights`\\n\\nPlease let me know if you would like to book a flight or need further assistance.', 'additional_kwargs': {}, 'response_metadata': {'token_usage': {'completion_tokens': 231, 'prompt_tokens': 3847, 'total_tokens': 4078, 'completion_time': 0.750891901, 'prompt_time': 0.283432514, 'queue_time': 0.271291283, 'total_time': 1.034324415}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_de9fa14705', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': 'flight_agent', 'id': 'run--150899d5-c128-4ff7-966f-5ed92653219d-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 3847, 'output_tokens': 231, 'total_tokens': 4078}}, {'content': 'Transferring back to supervisor', 'additional_kwargs': {}, 'response_metadata': {'__is_handoff_back': True}, 'type': 'ai', 'name': 'flight_agent', 'id': '02462c2c-8751-453d-83e1-73dca2128e33', 'example': False, 'tool_calls': [{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': 'af2595c5-6a57-4a67-9840-4ef454784f39', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': 'Successfully transferred back to supervisor', 'additional_kwargs': {}, 'response_metadata': {'__is_handoff_back': True}, 'type': 'tool', 'name': 'transfer_back_to_supervisor', 'id': 'aadadb4b-3417-47ec-bdb0-b66f7f23b575', 'tool_call_id': 'af2595c5-6a57-4a67-9840-4ef454784f39', 'artifact': None, 'status': 'success'}, {'content': 'Would you like to book one of the flights I listed earlier or would you like to search for hotels in Seattle?', 'additional_kwargs': {}, 'response_metadata': {'token_usage': {'completion_tokens': 24, 'prompt_tokens': 1374, 'total_tokens': 1398, 'completion_time': 0.065076749, 'prompt_time': 0.107235618, 'queue_time': 0.265405693, 'total_time': 0.172312367}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_de9fa14705', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': 'supervisor', 'id': 'run--f241839d-bad0-476b-84d2-cf0c3dffa440-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 1374, 'output_tokens': 24, 'total_tokens': 1398}}], 'status': 'success'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Example: Call a FastAPI endpoint (replace with your actual endpoint and payload)\n",
    "url = \"http://localhost:8000/chat\"\n",
    "payload = {\"message\": \"search flight from new york to seattle on 15/08/2015\",\"thread_id\":\"test\"}\n",
    "\n",
    "response = requests.post(url, json=payload)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9863dc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search flight from new york to seattle on 15/08/2015\n",
      "\n",
      "Successfully transferred to flight_agent\n",
      "**Flight Search Results**\n",
      "==========================\n",
      "\n",
      "Here are the search results for flights from New York to Seattle on 15/08/2015:\n",
      "\n",
      "**Flights Found:** 6\n",
      "\n",
      "**Flight Details:**\n",
      "\n",
      "* **Flight 1:** DL422, Departing JFK at 07:10, Arriving SEA at 10:07\n",
      "* **Flight 2:** DL467, Departing JFK at 10:45, Arriving SEA at 13:49\n",
      "* **Flight 3:** DL419, Departing JFK at 15:50, Arriving SEA at 19:15\n",
      "* **Flight 4:** B6263, Departing JFK at 17:36, Arriving SEA at 20:59\n",
      "* **Flight 5:** AA45, Departing JFK at 18:30, Arriving SEA at 22:05\n",
      "* **Flight 6:** DL427, Departing JFK at 18:50, Arriving SEA at 22:25\n",
      "\n",
      "**Tables Used:** `flights`\n",
      "\n",
      "Please let me know if you would like to book a flight or need further assistance.\n",
      "Transferring back to supervisor\n",
      "Successfully transferred back to supervisor\n",
      "Would you like to book one of the flights I listed earlier or would you like to search for hotels in Seattle?\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([i.get(\"content\") for i in response.json().get(\"messages\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29ae1faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph-prebuilt in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: langchain-core>=0.3.67 in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from langgraph-prebuilt) (0.3.68)\n",
      "Requirement already satisfied: langgraph-checkpoint>=2.1.0 in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from langgraph-prebuilt) (2.1.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from langchain-core>=0.3.67->langgraph-prebuilt) (0.4.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from langchain-core>=0.3.67->langgraph-prebuilt) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from langchain-core>=0.3.67->langgraph-prebuilt) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\prashant.kumar\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core>=0.3.67->langgraph-prebuilt) (6.0.2)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core>=0.3.67->langgraph-prebuilt)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\prashant.kumar\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core>=0.3.67->langgraph-prebuilt) (4.14.1)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from langchain-core>=0.3.67->langgraph-prebuilt) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.67->langgraph-prebuilt) (2.1)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from langgraph-checkpoint>=2.1.0->langgraph-prebuilt) (1.10.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.3.67->langgraph-prebuilt) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.3.67->langgraph-prebuilt) (3.10.14)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\prashant.kumar\\appdata\\roaming\\python\\python313\\site-packages (from langsmith>=0.3.45->langchain-core>=0.3.67->langgraph-prebuilt) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.3.67->langgraph-prebuilt) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.3.67->langgraph-prebuilt) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.67->langgraph-prebuilt) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\prashant.kumar\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.67->langgraph-prebuilt) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.67->langgraph-prebuilt) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\prashant.kumar\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.67->langgraph-prebuilt) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.67->langgraph-prebuilt) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from pydantic>=2.7.4->langchain-core>=0.3.67->langgraph-prebuilt) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from pydantic>=2.7.4->langchain-core>=0.3.67->langgraph-prebuilt) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from pydantic>=2.7.4->langchain-core>=0.3.67->langgraph-prebuilt) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\prashant.kumar\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.3.67->langgraph-prebuilt) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prashant.kumar\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.3.67->langgraph-prebuilt) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\prashant.kumar\\appdata\\local\\anaconda3\\envs\\llmops\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.67->langgraph-prebuilt) (1.3.0)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Installing collected packages: packaging\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed packaging-24.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.38.0 requires pillow<11,>=7.1.0, but you have pillow 11.3.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph-prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ce38d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_react_agent' from 'langgraph.prebuilt' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myaml\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magent_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConfigReactAgent\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# with open(\"config.yaml\") as f:\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#     config = yaml.safe_load(f)\u001b[39;00m\n\u001b[32m      7\u001b[39m flight_cfg = configs[\u001b[33m\"\u001b[39m\u001b[33magents\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mflight_agent\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_012\\core\\agent_builder.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_groq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGroq\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprebuilt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_react_agent\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'create_react_agent' from 'langgraph.prebuilt' (unknown location)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac42a284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8048c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a8f0ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "def load_tools(tool_paths):\n",
    "    loaded = {}\n",
    "    for path in tool_paths:\n",
    "        module_name, func_name = path.rsplit(\".\", 1)\n",
    "        module = importlib.import_module(module_name)\n",
    "        func = getattr(module, func_name)\n",
    "        loaded[func_name] = func\n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b544ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_agent_tools = load_tools(configs[\"agents\"][\"flight_agent\"][\"tools\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f5fcc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search_flights': StructuredTool(name='search_flights', description='CRITICAL: Use this tool or searching the flight for give, source, destination and day month and year.', args_schema=<class 'langchain_core.utils.pydantic.search_flights'>, func=<function search_flights at 0x0000024BA9D7EFC0>),\n",
       " 'save_flight_booking': StructuredTool(name='save_flight_booking', description='Critical: Save a booking to the database.', args_schema=<class 'langchain_core.utils.pydantic.save_flight_booking'>, func=<function save_flight_booking at 0x0000024B9988B240>),\n",
       " 'cancel_flight_booking': StructuredTool(name='cancel_flight_booking', description='Critical: Cancel a booking by booking_id.', args_schema=<class 'langchain_core.utils.pydantic.cancel_flight_booking'>, func=<function cancel_flight_booking at 0x0000024B9644E980>)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_agent_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "639da822",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "save_flight_booking() got an unexpected keyword argument 'travel_day'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mflight_agent_tools\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msave_flight_booking\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNew York\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseattle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtravel_day\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m15\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtravel_month\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtravel_year\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m2015\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: save_flight_booking() got an unexpected keyword argument 'travel_day'"
     ]
    }
   ],
   "source": [
    "flight_agent_tools[\"save_flight_booking\"].func(source=\"New York\", destination=\"seattle\", travel_day=\"15\", travel_month=\"8\", travel_year=\"2015\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c32220b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'func'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mflight_agent_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'func'"
     ]
    }
   ],
   "source": [
    "flight_agent_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915adba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'flight_agent_tools' from 'core.tools_builder' (d:\\Project_012\\core\\tools_builder.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (flight_agent_tools)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'flight_agent_tools' from 'core.tools_builder' (d:\\Project_012\\core\\tools_builder.py)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c890c145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tools': {'flights': [{'name': 'init_db', 'type': 'flights', 'return_direct': False, 'description': 'Initialize the bookings database and create the bookings table if it does not exist.', 'inputs': {'_': 'str'}, 'config': {'db_name': 'bookings.db', 'base_sql': 'CREATE TABLE IF NOT EXISTS bookings (\\n  flight_booking_id TEXT PRIMARY KEY,\\n  name TEXT,\\n  email TEXT,\\n  phone TEXT,\\n  source TEXT,\\n  destination TEXT,\\n  date TEXT,\\n  flight_id TEXT,\\n  status TEXT\\n);\\n'}, 'implementation': 'init_db'}]}}\n",
      "init_db\n",
      "CREATE TABLE IF NOT EXISTS bookings (\n",
      "  flight_booking_id TEXT PRIMARY KEY,\n",
      "  name TEXT,\n",
      "  email TEXT,\n",
      "  phone TEXT,\n",
      "  source TEXT,\n",
      "  destination TEXT,\n",
      "  date TEXT,\n",
      "  flight_id TEXT,\n",
      "  status TEXT\n",
      ");\n",
      "\n",
      "bookings.db\n"
     ]
    }
   ],
   "source": [
    "# from langchain.tools import Tool\n",
    "# import sqlite3\n",
    "\n",
    "# class BuildTool:\n",
    "#     def __init__(self,tools_configs=\"\"):\n",
    "#         try:\n",
    "#             self.configs = yaml.safe_load(open(tools_configs, \"r\"))\n",
    "#             print(self.configs)\n",
    "#         except FileNotFoundError:\n",
    "#             raise FileNotFoundError(\"Configuration file not found. Please check the path.\")\n",
    "        \n",
    "#         self.all_tools = {}\n",
    "  \n",
    "#         for groupname, tools_list in self.configs[\"tools\"].items():\n",
    "#             for i in tools_list:\n",
    "#                 if isinstance(i, dict) and \"name\" in i:\n",
    "#                     tool_name = i.get(\"name\")\n",
    "#                     print(tool_name)\n",
    "#                     if tool_name:\n",
    "#                         base_sql=f\"\"\"{i[\"config\"].get(\"base_sql\", \"\")}\"\"\"\n",
    "#                         print(base_sql)\n",
    "#                         conn = i[\"config\"].get(\"db_name\", \"\")\n",
    "#                         self.db_connect=sqlite3.connect(conn)\n",
    "#                         print(conn)\n",
    "#                         self.all_tools[tool_name] = Tool(\n",
    "# x = BuildTool(tools_configs=\"configs/test_tool.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0661c216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d18fa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.tools: [{'name': 'init_flight_db', 'description': 'Initialize the flight bookings database and create the bookings table if not exists.', 'function': 'init_flight_db', 'db_connection': 'flight_bookings.db', 'return_direct': False, 'base_query': 'CREATE TABLE IF NOT EXISTS bookings (\\n  booking_id TEXT PRIMARY KEY,\\n  name TEXT,\\n  email TEXT,\\n  phone TEXT,\\n  source TEXT,\\n  destination TEXT,\\n  date TEXT,\\n  flight_id TEXT,\\n  status TEXT\\n);\\n', 'kwargs': {'_': ''}}, {'name': 'search_flights', 'description': 'Use to search flights by source, destination, and travel date.', 'function': 'search_flights', 'db_conn': 'D:/flight_booking-20250820T042255Z-1-001/flight_booking/database/flights.db', 'return_direct': False, 'sql_query': \"SELECT \\n  f.*, \\n  a.* AS departure_airport_info, \\n  a2.* AS arrival_airport_info, \\n  al.* AS airline_info\\nFROM flights f\\nJOIN airports a ON f.ORIGIN_AIRPORT = a.IATA_CODE\\nJOIN airports a2 ON f.DESTINATION_AIRPORT = a2.IATA_CODE\\nJOIN airlines al ON f.AIRLINE = al.IATA_CODE\\nWHERE LOWER(a.CITY) LIKE LOWER('%{source}%')\\n  AND LOWER(a2.CITY) LIKE LOWER('%{destination}%')\\n  AND f.YEAR = {travel_year}\\n  AND f.MONTH = {travel_month}\\n  AND f.DAY = {travel_day};\\n\", 'kwargs': {'source': '', 'destination': '', 'travel_day': '', 'travel_month': '', 'travel_year': ''}}, {'name': 'save_flight_booking', 'description': 'Save a flight booking to the database.', 'function': 'save_flight_booking', 'db_connection': 'flight_bookings.db', 'return_direct': False, 'base_query': 'INSERT INTO bookings VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?);\\n', 'kwargs': {'name': '', 'email': '', 'phone': '', 'source': '', 'destination': '', 'date': '', 'flight_id': '', 'status': ''}}, {'name': 'cancel_flight_booking', 'description': 'Cancel a booking using booking_id.', 'function': 'cancel_flight_booking', 'db_connection': 'flight_bookings.db', 'return_direct': False, 'base_query': \"UPDATE bookings SET status = 'Cancelled' WHERE booking_id = ?;\\n\", 'kwargs': {'booking_id': ''}}, {'name': 'get_flight_booking_status', 'description': 'Get booking details and status by booking_id.', 'function': 'get_flight_booking_status', 'db_connection': 'flight_bookings.db', 'return_direct': False, 'base_query': 'SELECT * FROM bookings WHERE booking_id = ?;\\n', 'kwargs': {'booking_id': ''}}, {'name': 'init_hotel_db', 'description': 'Initialize the hotel bookings database and create hotel_bookings table if not exists.', 'function': 'init_hotel_db', 'db_connection': 'flight_bookings.db', 'return_direct': False, 'base_query': 'CREATE TABLE IF NOT EXISTS hotel_bookings (\\n  booking_id TEXT PRIMARY KEY,\\n  name TEXT,\\n  email TEXT,\\n  phone TEXT,\\n  hotel_name TEXT,\\n  check_in_date TEXT,\\n  check_out_date TEXT,\\n  status TEXT\\n);\\n', 'kwargs': {'_': ''}}]\n",
      "❌ search_flights: near \"AS\": syntax error\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'get_booking'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 161\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# print(tools['init_db'](\"\"))  # Initialize the database\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28mprint\u001b[39m(tools[\u001b[33m'\u001b[39m\u001b[33msearch_flights\u001b[39m\u001b[33m'\u001b[39m](\u001b[33m\"\u001b[39m\u001b[33msource=New York;destination=Los Angeles;travel_day=15;travel_month=8;travel_year=2023\u001b[39m\u001b[33m\"\u001b[39m))  \u001b[38;5;66;03m# Search flights)tools['save_booking'](\"booking_id=;name=John Doe;email=john@example.com;phone=1234567890;source=New York;destination=Los Angeles;date=2023-08-15;flight_id=FL123\")  # Save booking\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[43mtools\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mget_booking\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mbooking_id=BK2023081512345678\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# Get booking by ID\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28mprint\u001b[39m(tools[\u001b[33m'\u001b[39m\u001b[33mcancel_booking\u001b[39m\u001b[33m'\u001b[39m](\u001b[33m\"\u001b[39m\u001b[33mbooking_id=BK2023081512345678\u001b[39m\u001b[33m\"\u001b[39m))  \u001b[38;5;66;03m# Cancel booking by ID\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28mprint\u001b[39m(tools[\u001b[33m'\u001b[39m\u001b[33mget_booking\u001b[39m\u001b[33m'\u001b[39m](\u001b[33m\"\u001b[39m\u001b[33mbooking_id=BK2023081512345678\u001b[39m\u001b[33m\"\u001b[39m))  \u001b[38;5;66;03m# Verify cancellation\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'get_booking'"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "from langchain.tools import Tool\n",
    "import yaml\n",
    "\n",
    "\n",
    "class SimpleConfigTool:\n",
    "    def __init__(self, config_yaml: str):\n",
    "        if config_yaml.endswith(\".yaml\") or config_yaml.endswith(\".yml\"):\n",
    "            with open(config_yaml, \"r\") as f:\n",
    "                self.tools = yaml.safe_load(f)[\"tools\"]\n",
    "            print(f\"self.tools: {self.tools}\")\n",
    "        else:\n",
    "            self.tools = yaml.safe_load(config_yaml)[\"tools\"]\n",
    "    \n",
    "    def build_tools(self):\n",
    "        return {tool_config.get(\"name\") : self._make_tool(tool_config) for tool_config in self.tools}\n",
    "    \n",
    "    def _make_tool(self, config: Dict[str, Any]) -> Tool:\n",
    "        def tool_func(input_str: str = \"\", **kwargs) -> str:\n",
    "            # Parse parameters\n",
    "            params = dict(config.get('kwargs', {}))\n",
    "            \n",
    "            # Parse input_str \"key=val;key=val\"\n",
    "            for pair in input_str.split(';'):\n",
    "                if '=' in pair:\n",
    "                    k, v = pair.split('=', 1)\n",
    "                    params[k.strip()] = v.strip()\n",
    "            \n",
    "            params.update(kwargs)\n",
    "            \n",
    "            # Execute SQL\n",
    "            return self._execute_sql(\n",
    "                db_conn=config['db_conn'],\n",
    "                sql_query=config['sql_query'], \n",
    "                params=params,\n",
    "                toolname=config['name']\n",
    "            )\n",
    "        \n",
    "        return Tool(\n",
    "            name=config['name'],\n",
    "            description=config['description'],\n",
    "            func=tool_func\n",
    "        )\n",
    "    \n",
    "    def _execute_sql(self, db_conn: str, sql_query: str, params: Dict, toolname: str) -> str:\n",
    "        try:\n",
    "            with sqlite3.connect(db_conn) as conn:\n",
    "                conn.row_factory = sqlite3.Row\n",
    "                \n",
    "                # Handle different SQL types\n",
    "                if sql_query.strip().upper().startswith('CREATE'):\n",
    "                    conn.execute(sql_query)\n",
    "                    return f\"✅ {toolname}: Table created/ensured\"\n",
    "                \n",
    "                elif sql_query.strip().upper().startswith('SELECT'):\n",
    "                    # Replace {param} with values\n",
    "                    formatted_sql = sql_query.format(**params)\n",
    "                    rows = [dict(row) for row in conn.execute(formatted_sql).fetchall()]\n",
    "                    return json.dumps({\"results\": rows})\n",
    "                \n",
    "                elif sql_query.strip().upper().startswith('INSERT'):\n",
    "                    # Generate ID if needed\n",
    "                    if 'booking_id' in params and not params['booking_id']:\n",
    "                        params['booking_id'] = f\"BK{datetime.now().strftime('%Y%m%d%H%M%S')}{uuid.uuid4().hex[:8]}\"\n",
    "                    \n",
    "                    # Use ? placeholders\n",
    "                    values = tuple(params.get(k, '') for k in params.keys())\n",
    "                    conn.execute(sql_query, values)\n",
    "                    return json.dumps({\"status\": \"success\", \"id\": params.get('booking_id', 'created')})\n",
    "                \n",
    "                elif sql_query.strip().upper().startswith('UPDATE'):\n",
    "                    values = tuple(params.get(k, '') for k in params.keys())\n",
    "                    cursor = conn.execute(sql_query, values)\n",
    "                    return json.dumps({\"status\": \"updated\", \"rows\": cursor.rowcount})\n",
    "                \n",
    "                else:\n",
    "                    conn.execute(sql_query)\n",
    "                    return f\"✅ {toolname}: Executed\"\n",
    "                    \n",
    "        except Exception as e:\n",
    "            return f\"❌ {toolname}: {str(e)}\"\n",
    "\n",
    "\n",
    "# YAML Config with just 5 attributes\n",
    "# config_yaml = \"\"\"\n",
    "# tools:\n",
    "#   - toolname: init_db\n",
    "#     db_conn: bookings.db\n",
    "#     description: Initialize the bookings database\n",
    "#     sql_query: |\n",
    "#       CREATE TABLE IF NOT EXISTS bookings (\n",
    "#         booking_id TEXT PRIMARY KEY,\n",
    "#         name TEXT,\n",
    "#         email TEXT,\n",
    "#         phone TEXT,\n",
    "#         source TEXT,\n",
    "#         destination TEXT,\n",
    "#         date TEXT,\n",
    "#         flight_id TEXT,\n",
    "#         status TEXT\n",
    "#       )\n",
    "#     kwargs: {}\n",
    "\n",
    "#   - toolname: search_flights\n",
    "#     db_conn: flights.db  \n",
    "#     description: Search flights by source and destination\n",
    "#     sql_query: |\n",
    "#       SELECT f.FLIGHT_NUMBER, a.AIRPORT as departure, a2.AIRPORT as arrival \n",
    "#       FROM flights f\n",
    "#       JOIN airports a ON f.ORIGIN_AIRPORT = a.IATA_CODE\n",
    "#       JOIN airports a2 ON f.DESTINATION_AIRPORT = a2.IATA_CODE\n",
    "#       WHERE LOWER(a.CITY) LIKE '%{source}%' \n",
    "#       AND LOWER(a2.CITY) LIKE '%{destination}%'\n",
    "#       AND f.YEAR = {travel_year} AND f.MONTH = {travel_month} AND f.DAY = {travel_day}\n",
    "#     kwargs:\n",
    "#       source: \"\"\n",
    "#       destination: \"\"\n",
    "#       travel_day: \"\"\n",
    "#       travel_month: \"\"\n",
    "#       travel_year: \"\"\n",
    "\n",
    "#   - toolname: save_booking\n",
    "#     db_conn: bookings.db\n",
    "#     description: Save a flight booking\n",
    "#     sql_query: INSERT INTO bookings VALUES (?,?,?,?,?,?,?,?,?)\n",
    "#     kwargs:\n",
    "#       booking_id: \"\"\n",
    "#       name: \"\"\n",
    "#       email: \"\"\n",
    "#       phone: \"\"\n",
    "#       source: \"\"\n",
    "#       destination: \"\"\n",
    "#       date: \"\"\n",
    "#       flight_id: \"\"\n",
    "#       status: \"Confirmed\"\n",
    "\n",
    "#   - toolname: get_booking\n",
    "#     db_conn: bookings.db\n",
    "#     description: Get booking by ID\n",
    "#     sql_query: SELECT * FROM bookings WHERE booking_id = ?\n",
    "#     kwargs:\n",
    "#       booking_id: \"\"\n",
    "\n",
    "#   - toolname: cancel_booking\n",
    "#     db_conn: bookings.db\n",
    "#     description: Cancel booking by ID  \n",
    "#     sql_query: UPDATE bookings SET status = 'Cancelled' WHERE booking_id = ?\n",
    "#     kwargs:\n",
    "#       booking_id: \"\"\n",
    "# \"\"\"\n",
    "\n",
    "# Usage\n",
    "builder = SimpleConfigTool(\"./configs/workflow_configs/tools.yaml\")\n",
    "tools = builder.build_tools()\n",
    "# print(tools['init_db'](\"\"))  # Initialize the database\n",
    "print(tools['search_flights'](\"source=New York;destination=Los Angeles;travel_day=15;travel_month=8;travel_year=2023\"))  # Search flights)tools['save_booking'](\"booking_id=;name=John Doe;email=john@example.com;phone=1234567890;source=New York;destination=Los Angeles;date=2023-08-15;flight_id=FL123\")  # Save booking\n",
    "tools['get_booking'](\"booking_id=BK2023081512345678\")  # Get booking by ID\n",
    "print(tools['cancel_booking'](\"booking_id=BK2023081512345678\"))  # Cancel booking by ID\n",
    "print(tools['get_booking'](\"booking_id=BK2023081512345678\"))  # Verify cancellation\n",
    "# Test\n",
    "print(f\"Built {tools} tools\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6779d550",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_react_agent' from 'langgraph.prebuilt' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfastapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTTPException\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mworkflow_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WorkflowBuilder\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlibs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmlflow_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MLflowManager\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_012\\core\\workflow_builder.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myaml\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magent_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConfigReactAgent\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph_supervisor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_supervisor\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_012\\core\\agent_builder.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_groq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGroq\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprebuilt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_react_agent\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpoint\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MemorySaver\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'create_react_agent' from 'langgraph.prebuilt' (unknown location)"
     ]
    }
   ],
   "source": [
    "from fastapi import HTTPException\n",
    "from pydantic import BaseModel\n",
    "from core.workflow_builder import WorkflowBuilder\n",
    "import requests\n",
    "from libs.mlflow_utils import MLflowManager\n",
    "\n",
    "mlflow_manager = MLflowManager()\n",
    "builder = WorkflowBuilder()\n",
    "\n",
    "class ComboEvalRequest(BaseModel):\n",
    "    agent_name: str\n",
    "    model_names: list\n",
    "    prompts: list\n",
    "    test_data_url: str\n",
    "    thread_id: str = \"eval\"\n",
    "\n",
    "def evaluate_all_agents(request: ComboEvalRequest):\n",
    "    try:\n",
    "        # Fetch test dataset\n",
    "        resp = requests.get(request.test_data_url)\n",
    "        resp.raise_for_status()\n",
    "        test_data = resp.json()  # [{\"input\": \"...\", \"expected\": \"...\"}]\n",
    "\n",
    "        all_agent_results = {}\n",
    "\n",
    "        for agent_name, agent in builder.agents.items():\n",
    "            best_combo = None\n",
    "            best_accuracy = -1\n",
    "            all_results = []\n",
    "\n",
    "            for model_name in request.model_names:\n",
    "                builder.model_name = model_name\n",
    "                builder.load_model()\n",
    "                for prompt in request.prompts:\n",
    "                    if hasattr(builder, \"prompt\"):\n",
    "                        builder.prompt = prompt\n",
    "                    correct = 0\n",
    "                    total = 0\n",
    "                    for item in test_data:\n",
    "                        user_input = item.get(\"input\")\n",
    "                        expected = item.get(\"expected\")\n",
    "                        result = agent.run(user_input, request.thread_id)\n",
    "                        output = str(result)\n",
    "                        if expected and expected in output:\n",
    "                            correct += 1\n",
    "                        total += 1\n",
    "                    accuracy = correct / total if total else 0\n",
    "                    all_results.append({\n",
    "                        \"model\": model_name,\n",
    "                        \"prompt\": prompt,\n",
    "                        \"accuracy\": accuracy\n",
    "                    })\n",
    "                    if accuracy > best_accuracy:\n",
    "                        best_accuracy = accuracy\n",
    "                        best_combo = {\"model\": model_name, \"prompt\": prompt, \"accuracy\": accuracy}\n",
    "\n",
    "            all_agent_results[agent_name] = {\n",
    "                \"best_combo\": best_combo,\n",
    "                \"all_results\": all_results\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            \"results\": all_agent_results,\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Fill with your actual values\n",
    "    request = ComboEvalRequest(\n",
    "        agent_name=\"flight_agent\",\n",
    "        model_names=[\"llama3-70b-8192\", \"other_model\"],\n",
    "        prompts=[\"Prompt A\", \"Prompt B\"],\n",
    "        test_data_url=\"http://your-test-data-api/dataset\"\n",
    "    )\n",
    "    result = evaluate_all_agents(request)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1335ebb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLflow experiment: genai_ops_demo\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "from libs.mlflow_utils import MLflowManager, mlflow_run\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "EXPERIMENT = os.getenv(\"EXPERIMENT\")\n",
    "print(f\"Using MLflow experiment: {EXPERIMENT}\")\n",
    "MLflowManager(experiment=EXPERIMENT)\n",
    "\n",
    "\n",
    "# class RegisterModelReq(BaseModel):\n",
    "#     model_name: str\n",
    "#     model_uri: str\n",
    "#     description: str | None = None\n",
    "#     tags: dict | None = None\n",
    "\n",
    "client = MlflowClient()\n",
    "        # Register the model\n",
    "mv = client.create_registered_model(name=\"llama3-70b-8192\", tags={\"provider\": \"groq\"}, description=\"\")\n",
    "mv = client.create_registered_model(name=\"llama3-8b-8192\", tags={\"provider\": \"groq\"}, description=\"\")\n",
    "mv = client.create_registered_model(name=\"llama-3-Groq-8B-Tool-Use\", tags={\"provider\": \"groq\"}, description=\"\")\n",
    "\n",
    "\n",
    "\n",
    "# Create a new model version\n",
    "# print(client.search_registered_models())\n",
    "# # @app.post(\"/register/model\")\n",
    "# # @governed\n",
    "# # @mlflow_run(\"model_registry_register\")\n",
    "\n",
    "# # async def register_model(req: RegisterModelReq):\n",
    "# #     \"\"\"Register a model in the MLflow Model Registry.\"\"\"\n",
    "# #     try:\n",
    "# #         client = MlflowClient()\n",
    "# #         # Register the model\n",
    "# #         mv = client.create_registered_model(name=req.model_name, tags=req.tags or {}, description=req.description or \"\")\n",
    "# #         # Create a new model version\n",
    "# #         version = client.create_model_version(name=req.model_name, source=req.model_uri, run_id=None)\n",
    "# #         return {\n",
    "# #             \"status\": \"ok\",\n",
    "# #             \"name\": req.model_name,\n",
    "# #             \"version\": version.version,\n",
    "# #             \"model_uri\": req.model_uri,\n",
    "# #             \"description\": req.description,\n",
    "# #         }\n",
    "# #     except Exception as e:\n",
    "# #         raise HTTPException(status_code=500, detail=f\"Failed to register model: {str(e)}\")\n",
    "\n",
    "# # @app.get(\"/models/{model_name}\")\n",
    "# # def get_model_details(model_name: str):\n",
    "# #     \"\"\"Get details for a registered model.\"\"\"\n",
    "# #     try:\n",
    "# #         client = MlflowClient()\n",
    "# #         model = client.get_registered_model(model_name)\n",
    "# #         versions = client.get_latest_versions(model_name)\n",
    "# #         return {\n",
    "# #             \"name\": model.name,\n",
    "# #             \"description\": model.description,\n",
    "# #             \"tags\": model.tags,\n",
    "# #             \"latest_versions\": [\n",
    "# #                 {\n",
    "# #                     \"version\": v.version,\n",
    "# #                     \"status\": v.status,\n",
    "# #                     \"run_id\": v.run_id,\n",
    "# #                     \"source\": v.source,\n",
    "# #                     \"creation_timestamp\": v.creation_timestamp,\n",
    "# #                 }\n",
    "# #                 for v in versions\n",
    "# #             ]\n",
    "# #         }\n",
    "# #     except Exception as e:\n",
    "# #         raise HTTPException(status_code=404, detail=f\"Model '{model_name}' not found: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07312d62",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m      3\u001b[39m ds = load_dataset(\u001b[33m\"\u001b[39m\u001b[33mknkarthick/samsum\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"knkarthick/samsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77b0b4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting filelock (from datasets)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from datasets) (15.0.2)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.15-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.6.4-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl.metadata (76 kB)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prashant kumar\\.conda\\envs\\genai\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading aiohttp-3.12.15-cp311-cp311-win_amd64.whl (453 kB)\n",
      "Downloading multidict-6.6.4-cp311-cp311-win_amd64.whl (46 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl (86 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "   ---------------------------------------- 0.0/561.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 561.5/561.5 kB 20.0 MB/s eta 0:00:00\n",
      "Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl (41 kB)\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: propcache, multidict, fsspec, frozenlist, filelock, dill, attrs, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "\n",
      "   ----- ----------------------------------  2/14 [fsspec]\n",
      "   ----- ----------------------------------  2/14 [fsspec]\n",
      "   ----- ----------------------------------  2/14 [fsspec]\n",
      "   ----------- ----------------------------  4/14 [filelock]\n",
      "   -------------- -------------------------  5/14 [dill]\n",
      "   -------------- -------------------------  5/14 [dill]\n",
      "   -------------------- -------------------  7/14 [aiohappyeyeballs]\n",
      "   ------------------------- --------------  9/14 [multiprocess]\n",
      "   ------------------------- --------------  9/14 [multiprocess]\n",
      "   ---------------------------- ----------- 10/14 [huggingface-hub]\n",
      "   ---------------------------- ----------- 10/14 [huggingface-hub]\n",
      "   ---------------------------- ----------- 10/14 [huggingface-hub]\n",
      "   ---------------------------- ----------- 10/14 [huggingface-hub]\n",
      "   ---------------------------- ----------- 10/14 [huggingface-hub]\n",
      "   ---------------------------- ----------- 10/14 [huggingface-hub]\n",
      "   ---------------------------- ----------- 10/14 [huggingface-hub]\n",
      "   ------------------------------- -------- 11/14 [aiosignal]\n",
      "   ---------------------------------- ----- 12/14 [aiohttp]\n",
      "   ---------------------------------- ----- 12/14 [aiohttp]\n",
      "   ---------------------------------- ----- 12/14 [aiohttp]\n",
      "   ------------------------------------- -- 13/14 [datasets]\n",
      "   ------------------------------------- -- 13/14 [datasets]\n",
      "   ------------------------------------- -- 13/14 [datasets]\n",
      "   ------------------------------------- -- 13/14 [datasets]\n",
      "   ------------------------------------- -- 13/14 [datasets]\n",
      "   ---------------------------------------- 14/14 [datasets]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 attrs-25.3.0 datasets-4.0.0 dill-0.3.8 filelock-3.19.1 frozenlist-1.7.0 fsspec-2025.3.0 huggingface-hub-0.34.4 multidict-6.6.4 multiprocess-0.70.16 propcache-0.3.2 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc1b6d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PRASHANT KUMAR\\.conda\\envs\\genai\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "c:\\Users\\PRASHANT KUMAR\\.conda\\envs\\genai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\PRASHANT KUMAR\\.conda\\envs\\genai\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\PRASHANT KUMAR\\.cache\\huggingface\\hub\\datasets--knkarthick--samsum. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 14732/14732 [00:00<00:00, 99733.18 examples/s] \n",
      "Generating validation split: 100%|██████████| 818/818 [00:00<00:00, 67777.02 examples/s]\n",
      "Generating test split: 100%|██████████| 819/819 [00:00<00:00, 25647.01 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from datasets import load_dataset # Keep load_dataset from datasets\n",
    "# from evaluate import load # Import load from evaluate\n",
    "# import numpy as np\n",
    "\n",
    "# Load samsum dataset\n",
    "dataset = load_dataset('knkarthick/samsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "092f97a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 14732\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 818\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 819\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc3e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
